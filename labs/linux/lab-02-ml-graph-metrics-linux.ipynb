{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-title",
   "metadata": {},
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 8810: Machine Learning for Graphs</h1></div>\n",
    "     <img style=\"float: right; padding-right: 10px\" width=\"100\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div>\n",
    "     </div>\n",
    "\n",
    "**Clemson University**<br>\n",
    "**Instructor(s):** Aaron Masino <br>\n",
    "\n",
    "## Lab 2: Network Feature Engineering and Traditional Machine Learning\n",
    "\n",
    "This notebook demonstrates traditional machine learning approaches for graph related tasks using node metrics (such as centrality and groups) and graph metrics (such as density). This is analagous to the traditional approaches to image classifcation prior to the development of deep-learning models such as convolutional neural networks (CNNs). Before CNNs, researchers developed a large body of image metrics, so-called feature engineering, to support image classification using a variety of algorithmic approaches including standard machine learning methods like logistic regression and tree ensembles. With CNNs, nearly all current models work directly with the image and learn a useful, though latent, feature representation as part of the learning process. Similarly, researchers have developed numerous graph metrics that can be viewed as engineered features and used them for prediction tasks as input to standard machine learning methods.\n",
    "\n",
    "### Learning Objectives\n",
    "1. Apply NetworkX to compute and organize graph metrics in preparation for machine learning model development\n",
    "2. Understand the differences in graph metric behavior using numerical analysis and visualization methods\n",
    "3. Create machine learning models to predict graph node attributes using node metrics\n",
    "4. Evaluate the performance of machine learning models for graph node attribute prediction\n",
    "5. Create machine learning models to predict graph attributes using input graph metrics\n",
    "6. Evaluate the performance of machine learning models for graph attribute prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Library Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from itertools import cycle\n",
    "import random\n",
    "\n",
    "# Graph analysis\n",
    "import networkx as nx\n",
    "try:\n",
    "    import pygraphviz as pgv\n",
    "    PYGRAPHVIZ_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYGRAPHVIZ_AVAILABLE = False\n",
    "    print(\"Warning: pygraphviz not available. Network visualizations will be limited.\")\n",
    "\n",
    "# PyTorch and PyTorch Geometric\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           roc_auc_score, roc_curve, auc, accuracy_score,\n",
    "                           balanced_accuracy_score)\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create output directory\n",
    "# Set output directory for images and files\n",
    "output_dir = Path('./output/lab_02')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory created: {output_dir}\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Reusable random state\n",
    "RANDOM_STATE = 654321\n",
    "\n",
    "# Pandas set max columns to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sklearn-refresher-header",
   "metadata": {},
   "source": [
    "## 1. Scikit-learn Classification Refresher\n",
    "\n",
    "Let's first review key machine learning concepts using scikit-learn before diving into graph-specific analysis.\n",
    "\n",
    "### Key Concepts Covered\n",
    "1. **Train/Test Split**: Proper data partitioning for unbiased evaluation\n",
    "2. **Hyperparameter Tuning**: Grid search with cross-validation on training data\n",
    "3. **Model Evaluation**: Classification report, confusion matrix, ROC analysis\n",
    "\n",
    "As a review of fundamental machine learning practices using scikit-learn, let's build and evaluate a binary logistic regression classifier using the scikit-learn [breast cancer dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset). The model will predict between _benign_ and _malignant_.\n",
    "\n",
    "We begin by loading the dataset, splitting it into train and test sets, and standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sklearn-refresher-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example dataset (binary classification)\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names\n",
    "class_names = data.target_names\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"Classes: {class_names} (distribution: {np.bincount(y)})\")\n",
    "\n",
    "# TRAIN/TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"Training: {X_train.shape[0]} samples | Test: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Feature scaling (important for logistic regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6db98",
   "metadata": {},
   "source": [
    "### 1.1 Develop a logistic regression model\n",
    "Now, let's create an instance of the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) model. We also create a `param_grid` dictionary to hold the values of the model tuning parameters we wish to test.\n",
    "\n",
    "Next, we create an instance of [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to perform a nested grid search with cross-validation to identify the best hyperparameters. \n",
    "\n",
    "Finally, using the `grid_search` pipeline, we fit the model to the training data and identify the best hyperparameter combination. Because we set `refit=True` in the `GridSearchCV` inputs, the `grid_search` object will retrain the model with all training data for the optimal hyperparameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING WITH CROSS-VALIDATION\n",
    "# Create base model\n",
    "lr = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE, max_iter=1000)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2']               # Regularization type\n",
    "}\n",
    "\n",
    "\n",
    "# Grid search with cross-validation (on training data only)\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "grid_search = GridSearchCV(\n",
    "    lr, param_grid, cv=cv_strategy, scoring='roc_auc', n_jobs=-1, refit=True\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV ROC-AUC: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Get best model (already retrained on full training set)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082b481",
   "metadata": {},
   "source": [
    "### 1.2 Evaluating model performance\n",
    "Now that we've selected our optimal tuning parameters and trained the model, let's evaluate performance on the test set. We will create a confusion matrix and an ROC plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629070ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_proba = best_model.predict_proba(X_test_scaled)[:, 1]  # Probability of positive class\n",
    "\n",
    "# 3a. Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# 3b. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# 3c. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', alpha=0.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eed72c",
   "metadata": {},
   "source": [
    "# 2. Enron Dataset Node Classification\n",
    "Here we will consider the [Enron Email Dataset](https://snap.stanford.edu/data/email-Enron.html). The dataset represents email exchanges among Enron employees, primarily senior staff. Nodes of the network are email addresses and if an address i sent at least one email to address j, the graph contains an undirected edge from i to j. The complete network contains about 37,000 nodes, though here we will work with a subset of about 4,000 nodes.\n",
    "\n",
    "What's Enron? The [Enron scandal](https://en.wikipedia.org/wiki/Enron_scandal) was an accounting scandal sparked by American energy company Enron Corporation filing for bankruptcy after news of widespread internal fraud became public in October 2001. Shareholders filed a $40 billion lawsuit, for which they were eventually partially compensated $7.2 billion, after the company's stock price plummeted from a high of US$90.75 per share in mid-1990s to less than $1 by the end of November 2001. This email data was originally made public, and posted to the web, by the Federal Energy Regulatory Commission during its investigation.\n",
    "\n",
    "Let's start by loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afaa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/enron/enron_connected_subgraph.pkl', 'rb') as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "labels = [G.nodes[node]['label'] for node in G.nodes()]\n",
    "class_names = []\n",
    "\n",
    "with open('../data/enron/label_mapping.csv', 'r') as f:\n",
    "    # skip the header\n",
    "    f.readline()\n",
    "    class_names = [line.strip().split(',')[1] for line in f.readlines()]\n",
    "\n",
    "print(\"Distinct class names:\\n\",class_names)\n",
    "enron_class_names = class_names\n",
    "\n",
    "print(\"Number of nodes in the graph:\", len(G.nodes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e21a5",
   "metadata": {},
   "source": [
    "### 2.1 Data Visualization and Exploration\n",
    "\n",
    "Understanding the structure of our data is crucial before applying machine learning models. We'll examine:\n",
    "\n",
    "1. **Class Distribution**: How balanced are the 5 employee catagories?\n",
    "2. **Network Structure**: Visual representation of the citation network with node colors representing classes\n",
    "\n",
    "**Visualization Tools**:\n",
    "- **Matplotlib/Seaborn**: For statistical plots and class distributions\n",
    "- **NetworkX + Pygraphviz**: For network layout and visualization ([NetworkX docs](https://networkx.org/documentation/stable/), [Pygraphviz docs](https://pygraphviz.github.io/documentation/stable/))\n",
    "- **Interactive features**: Zoom capabilities if supported by the visualization backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_NETWORK_VISUALIZATION = False\n",
    "\n",
    "if PLOT_NETWORK_VISUALIZATION:\n",
    "    print(\"Creating network visualization, this may take several minutes...\")\n",
    "\n",
    "    # Prepare node colors based on classes\n",
    "    node_colors = [labels[node] for node in G.nodes()]\n",
    "    color_palette = sns.color_palette(\"husl\", len(class_names))\n",
    "    node_color_map = [color_palette[color] for color in node_colors]\n",
    "\n",
    "    # Create network visualization\n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "# Choose layout based on pygraphviz availability\n",
    "if PYGRAPHVIZ_AVAILABLE and PLOT_NETWORK_VISUALIZATION:\n",
    "    print(\"Using Pygraphviz for high-quality layout...\")\n",
    "    try:\n",
    "        # Use graphviz layout for better visualization\n",
    "        pos = nx.nx_agraph.graphviz_layout(G, prog='sfdp', args='-Goverlap=false -Gsplines=true')\n",
    "        layout_used = \"Graphviz SFDP\"\n",
    "    except Exception as e:\n",
    "        print(f\"Graphviz layout failed: {e}. Falling back to spring layout.\")\n",
    "        pos = nx.spring_layout(G, k=1, iterations=50, seed=42)\n",
    "        layout_used = \"Spring Layout (fallback)\"\n",
    "elif PLOT_NETWORK_VISUALIZATION:\n",
    "    print(\"Using NetworkX spring layout...\")\n",
    "    pos = nx.spring_layout(G, k=1, iterations=50, seed=42)\n",
    "    layout_used = \"Spring Layout\"\n",
    "\n",
    "# Draw the network\n",
    "if PLOT_NETWORK_VISUALIZATION:\n",
    "    nx.draw_networkx_nodes(G, pos, \n",
    "                          node_color=node_color_map,\n",
    "                          node_size=50,\n",
    "                          alpha=0.8,\n",
    "                          linewidths=0.5,\n",
    "                          edgecolors='black')\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3, width=0.3, edge_color='gray')\n",
    "\n",
    "    # Add node labels (showing node IDs)\n",
    "    # For readability, only show labels for a subset of nodes\n",
    "    if len(G.nodes()) <= 500:  # Show all labels for smaller graphs\n",
    "        nx.draw_networkx_labels(G, pos, font_size=6, font_color='black', alpha=0.7)\n",
    "    else:  # Show labels for every 10th node to avoid overcrowding\n",
    "        label_dict = {node: str(node) for i, node in enumerate(G.nodes()) if i % 10 == 0}\n",
    "        nx.draw_networkx_labels(G, pos, labels=label_dict, font_size=6, font_color='black', alpha=0.7)\n",
    "\n",
    "    plt.title(f'Enron Employee Network\\n{G.number_of_nodes()} nodes, {G.number_of_edges()} edges\\nLayout: {layout_used}', \n",
    "        fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "    # Create legend\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=color_palette[i], markersize=10,\n",
    "                             label=class_names[i].replace('_', ' '))\n",
    "                        for i in range(len(class_names))]\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.02, 1), \n",
    "            title='Role', title_fontsize=12, fontsize=10)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save high-resolution version\n",
    "    plt.savefig(output_dir / 'enron_network.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b0e58",
   "metadata": {},
   "source": [
    "Now, let's examine the class distribution of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numpy for easier manipulation\n",
    "denom = len(labels)\n",
    "class_counts = Counter(labels)\n",
    "\n",
    "# Create class distribution visualization\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# Bar plot\n",
    "bars = ax1.bar(range(len(enron_class_names)), [class_counts[i] for i in range(len(enron_class_names))], \n",
    "               color=sns.color_palette(\"husl\", len(enron_class_names)), alpha=0.8)\n",
    "ax1.set_xlabel('Role', fontsize=12)\n",
    "ax1.set_ylabel('Number of Employees', fontsize=12)\n",
    "ax1.set_title('Enron: Class Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(len(enron_class_names)))\n",
    "ax1.set_xticklabels([name.replace('_', '\\n') for name in enron_class_names], rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "             f'{int(height)} ({(height/denom)*100:.1f}%)', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'enron_class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961af40e",
   "metadata": {},
   "source": [
    "### 2.2 Graph-Based Feature Engineering: Node Centrality & Group Measures\n",
    "\n",
    "Node centrality measures capture the structural importance of nodes within the network. These features encode different aspects of a node's position and influence in the network. Node group measures provide an indication of the size and structure of communities that form within the graph. We anticipate that employees with different roles will have different influence within the network and belong to different groups, hence centrality and group metrics should be predictive of employee role.\n",
    "\n",
    "### Centrality Measures Overview\n",
    "\n",
    "1. **Degree Centrality**: Number of connections \n",
    "   - *Interpretation*: The number of employees to whom this person sends or recieves email \n",
    "   - *NetworkX*: [`nx.degree_centrality()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.degree_centrality.html)\n",
    "\n",
    "2. **Eigenvector Centrality**: Importance based on connections to other important nodes\n",
    "   - *Interpretation*: The importance of the employee relative to the importance of to whom they send/recieve email\n",
    "   - *NetworkX*: [`nx.eigenvector_centrality()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.eigenvector_centrality.html)\n",
    "\n",
    "3. **PageRank**: Google's algorithm measuring node importance via random walks\n",
    "   - *Interpretation*: Employes likely to be reached by random email chain browsing\n",
    "   - *NetworkX*: [`nx.pagerank()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html)\n",
    "\n",
    "4. **Clustering Coefficient**: Measure of local network density around a node\n",
    "   - *Interpretation*: Employees in tightly connected communities\n",
    "   - *NetworkX*: [`nx.clustering()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.cluster.clustering.html)\n",
    "\n",
    "5. **Betweenness Centrality**: Frequency of node appearing on shortest paths\n",
    "   - *Interpretation*: Employees that bridge different roles or departments\n",
    "   - *NetworkX*: [`nx.betweenness_centrality()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html)\n",
    "\n",
    "6. **Largest Clique**: The number of nodes in the largest maximal clique containing a given node\n",
    "   - *Interpretation*: The largest group of employees to which this node belongs and all group members exchange emails\n",
    "   - *NetworkX*: [`nx.node_clique_number()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.clique.node_clique_number.html#networkx.algorithms.clique.node_clique_number)\n",
    "\n",
    "7. **Clique Count**: The number of maximal cliques containing the node\n",
    "   - *Interpretation*: The number of distinct groups this employee is a member of\n",
    "   - *NetworkX*: [`nx.node_clique_number()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.clique.node_clique_number.html#networkx.algorithms.clique.node_clique_number)\n",
    "\n",
    "**Note**: All centrality measures are normalized and any NaN values are replaced with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3627c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize progress tracking\n",
    "centrality_measures = {}\n",
    "computation_times = {}\n",
    "\n",
    "import time\n",
    "\n",
    "# 1. Degree Centrality\n",
    "print(\"\\n[1/7] Computing degree centrality...\")\n",
    "start_time = time.time()\n",
    "degree_cent = nx.degree_centrality(G)\n",
    "computation_times['degree'] = time.time() - start_time\n",
    "print(f\"   Completed in {computation_times['degree']:.2f} seconds\")\n",
    "\n",
    "# 2. Eigenvector Centrality (with error handling)\n",
    "print(\"\\n[2/7] Computing eigenvector centrality...\")\n",
    "start_time = time.time()\n",
    "try:\n",
    "    eigen_cent = nx.eigenvector_centrality(G, max_iter=1000, tol=1e-06)\n",
    "    computation_times['eigenvector'] = time.time() - start_time\n",
    "    print(f\"   Completed in {computation_times['eigenvector']:.2f} seconds\")\n",
    "except nx.NetworkXError as e:\n",
    "    print(f\"   Warning: Eigenvector centrality failed ({e}). Using zeros.\")\n",
    "    eigen_cent = {node: 0.0 for node in G.nodes()}\n",
    "    computation_times['eigenvector'] = time.time() - start_time\n",
    "\n",
    "# 3. PageRank\n",
    "print(\"\\n[3/7] Computing PageRank...\")\n",
    "start_time = time.time()\n",
    "pagerank_cent = nx.pagerank(G, alpha=0.85, max_iter=1000, tol=1e-06)\n",
    "computation_times['pagerank'] = time.time() - start_time\n",
    "print(f\"   Completed in {computation_times['pagerank']:.2f} seconds\")\n",
    "\n",
    "# 4. Clustering Coefficient\n",
    "print(\"\\n[4/7] Computing clustering coefficient...\")\n",
    "start_time = time.time()\n",
    "clustering_coeff = nx.clustering(G)\n",
    "computation_times['clustering'] = time.time() - start_time\n",
    "print(f\"   Completed in {computation_times['clustering']:.2f} seconds\")\n",
    "\n",
    "# 5. Betweenness Centrality (most computationally expensive)\n",
    "print(\"\\n[5/7] Computing betweenness centrality...\")\n",
    "print(\"   This is the most computationally intensive measure...\")\n",
    "start_time = time.time()\n",
    "betweenness_cent = nx.betweenness_centrality(G, normalized=True, seed=RANDOM_STATE)\n",
    "computation_times['betweenness'] = time.time() - start_time\n",
    "print(f\"   Completed in {computation_times['betweenness']:.2f} seconds\")\n",
    "\n",
    "# 6. Largest Clique\n",
    "print(\"\\n[6/7] Computing largest clique...\")\n",
    "start_time = time.time()\n",
    "largest_clique = nx.node_clique_number(G)\n",
    "computation_times['largest_clique'] = time.time() - start_time\n",
    "print(f\"   Completed in {computation_times['largest_clique']:.2f} seconds\")\n",
    "\n",
    "# 7. Clique Count\n",
    "print(\"\\n[7/7] Computing clique count...\")\n",
    "start_time = time.time()\n",
    "clique_count = nx.number_of_cliques(G)\n",
    "computation_times['clique_count'] = time.time() - start_time\n",
    "print(f\"   Completed in {computation_times['clique_count']:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nTotal computation time: {sum(computation_times.values()):.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf991bd",
   "metadata": {},
   "source": [
    "Before we use these metrics to develop a machine learning model, let's examine their distributions. This will help us get a sense of the variance and range. Recall, that to inform a statistical learning model, the features must have some variance. Though, the presence of variance is not a guarantee that a machine learning model will perform well. The features must also carry information that is correlated to the outcome label.\n",
    "\n",
    "First, we'll organize the features into a numpy array and then a Pandas DataFrame for convenience with our visualization and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ed53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ordered arrays (matching node order in data.x)\n",
    "node_order = sorted(G.nodes())\n",
    "\n",
    "# Create centrality feature matrix\n",
    "centrality_features = {\n",
    "    'degree': np.array([degree_cent[node] for node in node_order]),\n",
    "    'eigenvector': np.array([eigen_cent[node] for node in node_order]),\n",
    "    'pagerank': np.array([pagerank_cent[node] for node in node_order]),\n",
    "    'clustering': np.array([clustering_coeff[node] for node in node_order]),\n",
    "    'betweenness': np.array([betweenness_cent[node] for node in node_order]),\n",
    "    'largest_clique': np.array([largest_clique[node] for node in node_order]),\n",
    "    'clique_count': np.array([clique_count[node] for node in node_order])\n",
    "}\n",
    "\n",
    "# Check for and replace NaN values\n",
    "print(\"\\nChecking for NaN values...\")\n",
    "for feature_name, feature_values in centrality_features.items():\n",
    "    nan_count = np.isnan(feature_values).sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"   {feature_name}: {nan_count} NaN values found - replacing with 0\")\n",
    "        centrality_features[feature_name] = np.nan_to_num(feature_values, nan=0.0)\n",
    "    else:\n",
    "        print(f\"   {feature_name}: No NaN values found\")\n",
    "\n",
    "# Create combined centrality feature matrix\n",
    "centrality_matrix = np.column_stack([\n",
    "    centrality_features['degree'],\n",
    "    centrality_features['eigenvector'],\n",
    "    centrality_features['pagerank'],\n",
    "    centrality_features['clustering'],\n",
    "    centrality_features['betweenness'],\n",
    "    centrality_features['largest_clique'],\n",
    "    centrality_features['clique_count']\n",
    "])\n",
    "\n",
    "print(f\"\\nCentrality feature matrix shape: {centrality_matrix.shape}\")\n",
    "\n",
    "# Compute statistics\n",
    "feature_names = ['Degree', 'Eigenvector', 'PageRank', 'Clustering', 'Betweenness', 'Largest Clique', 'Clique Count']\n",
    "feature_keys = [k for k in centrality_features.keys()]\n",
    "stats_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean': [np.mean(centrality_features[name]) for name in feature_keys],\n",
    "    'Std': [np.std(centrality_features[name]) for name in feature_keys],\n",
    "    'Min': [np.min(centrality_features[name]) for name in feature_keys],\n",
    "    'Max': [np.max(centrality_features[name]) for name in feature_keys],\n",
    "    'Zeros': [np.sum(centrality_features[name] == 0) for name in feature_keys]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Centrality Measures Statistics ===\")\n",
    "print(stats_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bbfde0",
   "metadata": {},
   "source": [
    "Now, let's create histograms and kernel density estimates for each of the node metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001090b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the plot array (2x4 grid)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 16))\n",
    "axes = axes.ravel()  # Flatten for easier indexing\n",
    "\n",
    "colors = sns.color_palette(\"husl\", len(feature_names))\n",
    "\n",
    "for i, (feature_name, color) in enumerate(zip(feature_names, colors)):\n",
    "    feature_key = feature_keys[i]\n",
    "    values = centrality_features[feature_key]\n",
    "    \n",
    "    # Create histogram with density curve\n",
    "    axes[i].hist(values, bins=50, density=True, alpha=0.7, color=color, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Add density curve\n",
    "    if np.std(values) > 0:  # Only if there's variation\n",
    "        kde_x = np.linspace(values.min(), values.max(), 100)\n",
    "        try:\n",
    "            from scipy import stats\n",
    "            kde = stats.gaussian_kde(values)\n",
    "            axes[i].plot(kde_x, kde(kde_x), color='darkred', linewidth=2, alpha=0.8)\n",
    "        except ImportError:\n",
    "            # Fallback if scipy not available\n",
    "            pass\n",
    "    \n",
    "    # Customize subplot\n",
    "    axes[i].set_title(f'{feature_name}\\nMean: {np.mean(values):.4f}, Std: {np.std(values):.4f}', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(f'{feature_name} Value', fontsize=10)\n",
    "    axes[i].set_ylabel('Density', fontsize=10)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical line for mean\n",
    "    axes[i].axvline(np.mean(values), color='red', linestyle='--', linewidth=2, alpha=0.8, label=f'Mean: {np.mean(values):.4f}')\n",
    "    axes[i].legend(fontsize=9)\n",
    "\n",
    "# Remove the empty subplot\n",
    "fig.delaxes(axes[7])\n",
    "\n",
    "# Add overall title\n",
    "fig.suptitle('Node Centrality & Group Measures Distribution\\nEnron Network', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'enron_centrality_group_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create correlation heatmap of centrality measures\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create correlation matrix\n",
    "centrality_df = pd.DataFrame(centrality_matrix, columns=feature_names)\n",
    "correlation_matrix = centrality_df.corr()\n",
    "\n",
    "# Create heatmap\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.title('Centrality & GroupMeasures Correlation Matrix\\nEnron Network', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'enron_centrality_group_correlations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729d225",
   "metadata": {},
   "source": [
    "### 2.3 Logistical Regression with Node Metrics\n",
    "\n",
    "We'll train and evaluate **logistic regression and random forest models** using the centrality measures to predict the employee role for a node.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. **Data Splitting**: Split the data into train/test splits of 80%, 20%. We'll use cross validation within the training set.\n",
    "2. **Model 1**: [Logistic Regression with regularization](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "3. **Hyperparameter Tuning**: [Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html) on training set to optimize regularization parameter (C) and regularization penalty. \n",
    "4. **Cross-validation Evaluation Metric**: [Balanced accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html) to handle class imbalance\n",
    "5. **Performance Analysis**: Classification reports, confusion matrices, and ROC-AUC curves\n",
    "\n",
    "First, let's split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X = centrality_matrix.copy()\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape} | Labels shape: {y.shape}\")\n",
    "\n",
    "# split the data into train/validation/test sets of 80% 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=RANDOM_STATE)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} samples | Test: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ebf61",
   "metadata": {},
   "source": [
    "Now let's develop the model. We'll use a grid search with k-fold cross validation to select the best regularization parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regularization parameter search space\n",
    "param_grid = {'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "             'penalty': ['l1', 'l2', 'elasticnet', 'none']}  # Regularization strengths\n",
    "\n",
    "# Create base model\n",
    "base_model = LogisticRegression(\n",
    "    solver='liblinear',  # Good for small datasets and L2 penalty\n",
    "    random_state=RANDOM_STATE,\n",
    "    max_iter=1000,\n",
    "    multi_class='ovr'  # One-vs-Rest for multiclass\n",
    ")\n",
    "\n",
    "# Grid search with balanced accuracy scoring\n",
    "grid_search = GridSearchCV(\n",
    "    base_model,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
    "    scoring='balanced_accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True  # Refit the best model on the entire training set\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "# Store the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best C: {grid_search.best_params_['C']}, Best penalty: {grid_search.best_params_['penalty']}\")\n",
    "print(f\"Best CV balanced accuracy: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Tuning completed in {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cff027",
   "metadata": {},
   "source": [
    "In reality, we would likely consider many alternative models during the training and evaluation process. For purposes of this lab, let's assume we've convinced ourselves that the logistic regression model is \"good enough\" and we'll use the optimal tuning parameters. \n",
    "\n",
    "Let's examine the test set results. We start with a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Pretty print classification report\n",
    "print(classification_report(y_test, y_test_pred, target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e3dc1",
   "metadata": {},
   "source": [
    "Let's also visualize the test results with a confustion matrix and ROC-AUC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fda01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_test_pred, normalize='pred')\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=axes)\n",
    "axes.set_xlabel('Predicted Label')\n",
    "axes.set_ylabel('True Label')\n",
    "axes.set_title('Enron Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xticks([_+0.5 for _ in range(len(enron_class_names))], enron_class_names, rotation=45, ha='center');\n",
    "plt.yticks([_+0.5 for _ in range(len(enron_class_names))], enron_class_names, rotation=45, ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'green', 'purple', 'brown'])\n",
    "\n",
    "# Binarize the output for multi-class ROC\n",
    "y_test_bin = label_binarize(y_test, classes=list(range(len(enron_class_names))))\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "# get the test set probabilities\n",
    "y_test_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "for j in range(n_classes):\n",
    "    fpr[j], tpr[j], _ = roc_curve(y_test_bin[:, j], y_test_proba[:, j])\n",
    "    roc_auc[j] = auc(fpr[j], tpr[j])\n",
    "\n",
    "for j, color in zip(range(n_classes), colors):\n",
    "        ax.plot(fpr[j], tpr[j], color=color, lw=2,\n",
    "               label=f'{class_names[j].replace(\"_\", \" \")} (AUC = {roc_auc[j]:.2f})')\n",
    "            \n",
    "# Plot random classifier line\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, alpha=0.5, label='Random (AUC = 0.50)')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
    "ax.set_title(f'Enron Network\\nPer-Class ROC Curves',fontsize=12, fontweight='bold')\n",
    "ax.legend(loc=\"lower right\", fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e04b9",
   "metadata": {},
   "source": [
    "Finally, let's look at the importance of the features by examining the coefficients of the features from the logistic regression model. Remember, we standardized the input features, so the absolute values of the logistic regression coefficients give us a measure of global feature importance for the model. Additionally, the sign of the coefficients indicate whether a positive increase in the feature results in an increase in the probability of class membership (positive coefficient) or a decrease in the probability of class membership (negative coeeficient.). Also, note, that in our model, we are consider multi-class classification using a one-vs-all approach, so we actually have one model per class and hence multiple sets of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f92d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = best_model.coef_\n",
    "# This is multi-class classification, so coeffs will have shape (n_classes, n_features)\n",
    "print(\"Logistic Regression Coefficients Shape:\")\n",
    "print(coeffs.shape)\n",
    "\n",
    "# create a DataFrame for better visualization\n",
    "coeffs_df = pd.DataFrame(coeffs, columns=feature_names, index=class_names)\n",
    "print(\"\\nLogistic Regression Coefficients:\")\n",
    "print(coeffs_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-forest-exercise-header",
   "metadata": {},
   "source": [
    "### 2.4 Random Forest with Graph Metrics\n",
    "Now let's create a random forest model to predict the role of Enron employees. We will use the same graph metrics as we did in our logistic regression model.\n",
    "\n",
    "#### **Excercise 2.1** \n",
    "Complete the code below to construct the `param_grid` dictionary so that the model training can evaluate the following hyperparameter values:\n",
    "- n_estimators: 50, 100, 200\n",
    "- max_depth: None, 5, 10\n",
    "- criteron: 'gini', 'entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f094b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.1\n",
    "param_grid = {\n",
    "# Your code here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8751fd",
   "metadata": {},
   "source": [
    "Now let's develop the Random Forest model.\n",
    "\n",
    "#### **Exercise 2.2**\n",
    "Complete the code below to fit the model to the data using the `grid_search` and to get the best estimator (i.e., the random forest model with the optimal hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "# Grid search with balanced accuracy scoring\n",
    "grid_search = GridSearchCV(\n",
    "    base_model,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE),\n",
    "    scoring='balanced_accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True  # Refit the best model on the entire training set\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.___ # Your code here\n",
    "\n",
    "# Store the best model\n",
    "best_model = ___ # Your code here\n",
    "\n",
    "print(f\"Best C: {grid_search.best_params_['n_estimators']}, Best max_depth: {grid_search.best_params_['max_depth']}, Best criterion: {grid_search.best_params_['criterion']}\")\n",
    "print(f\"Best CV balanced accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e00bf",
   "metadata": {},
   "source": [
    "Let's examine the performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_test_pred, target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3f5e1",
   "metadata": {},
   "source": [
    "Now let's examine the confustion matrix.\n",
    "\n",
    "#### **Exercise 2.3**\n",
    "Complete the code below to create the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "cm = ____ # Your code here\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=axes)\n",
    "axes.set_xlabel('Predicted Label')\n",
    "axes.set_ylabel('True Label')\n",
    "axes.set_title('Enron Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xticks([_+0.5 for _ in range(len(enron_class_names))], enron_class_names, rotation=45, ha='center');\n",
    "plt.yticks([_+0.5 for _ in range(len(enron_class_names))], enron_class_names, rotation=45, ha='right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed589fe6",
   "metadata": {},
   "source": [
    "Finally, let's also examine the ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dbae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "olors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'green', 'purple', 'brown'])\n",
    "\n",
    "# Binarize the output for multi-class ROC\n",
    "y_test_bin = label_binarize(y_test, classes=list(range(len(enron_class_names))))\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "y_test_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "for j in range(n_classes):\n",
    "    fpr[j], tpr[j], _ = roc_curve(y_test_bin[:, j], y_test_proba[:, j])\n",
    "    roc_auc[j] = auc(fpr[j], tpr[j])\n",
    "\n",
    "for j, color in zip(range(n_classes), colors):\n",
    "        ax.plot(fpr[j], tpr[j], color=color, lw=2,\n",
    "               label=f'{class_names[j].replace(\"_\", \" \")} (AUC = {roc_auc[j]:.2f})')\n",
    "            \n",
    "# Plot random classifier line\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, alpha=0.5, label='Random (AUC = 0.50)')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
    "ax.set_title(f'Enron Network\\nPer-Class ROC Curves',fontsize=12, fontweight='bold')\n",
    "ax.legend(loc=\"lower right\", fontsize=9)\n",
    "ax.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc13197",
   "metadata": {},
   "source": [
    "# 3. MUTAG Dataset Graph Classification\n",
    "\n",
    "In this section, we'll explore graph classification using the MUTAG dataset, which contains molecular structures labeled as mutagenic or non-mutagenic. Unlike the previous section where we predicted properties of individual nodes (employees), here we'll predict properties of entire graphs (molecules).\n",
    "\n",
    "The MUTAG dataset consists of 188 chemical compounds (graphs) where each compound is labeled as mutagenic (1) or non-mutagenic (0). Each node in the graph is one of 14 atoms:\n",
    "\n",
    "| Index | Atom |\n",
    "|-------|------|\n",
    "| 0     | C    |\n",
    "| 1     | O    |\n",
    "| 2     | Cl   |\n",
    "| 3     | H    |\n",
    "| 4     | N    |\n",
    "| 5     | F    |\n",
    "| 6     | Br   |\n",
    "| 7     | S    |\n",
    "| 8     | P    |\n",
    "| 9     | I    |\n",
    "| 10    | Na    |\n",
    "| 11    | K    |\n",
    "| 12    | Li    |\n",
    "| 13    | Ca    |\n",
    "\n",
    "### Key Differences from Node Classification:\n",
    "1. **Unit of Analysis**: Entire graphs instead of individual nodes\n",
    "2. **Features**: Graph-level metrics instead of node level (though we'll use average node leve, this type of aggregation will be common) \n",
    "3. **Task**: Binary classification of molecular mutagenicity\n",
    "4. **Metrics**: Graph structural properties like diameter, etc.\n",
    "\n",
    "Let's start by loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3l5tdkpm8pv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MUTAG dataset\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = TUDataset(root='../data/TUDataset', name='MUTAG')\n",
    "\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k84bhftfua",
   "metadata": {},
   "source": [
    "### 3.1 Data Visualization and Exploration\n",
    "\n",
    "It's generally a good idea to get a sense of the structure of the graphs in our dataset before applying machine learning models. We'll examine:\n",
    "\n",
    "1. **Sample Visualization**: Visual representation of molecular structures with atoms colored by type\n",
    "2. **Class Distribution**: Balance between mutagenic and non-mutagenic compounds\n",
    "3. **Graph Statistics**: Size characteristics (nodes/edges) across the dataset\n",
    "\n",
    "**Key Insights Expected**:\n",
    "- Molecular graphs are typically small (10-30 nodes) compared to other networks such as social networks\n",
    "- Graph connectivity patterns may differ between mutagenic and non-mutagenic compounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uvu4cbf0e6",
   "metadata": {},
   "source": [
    "First, let's visualize sample molecular graphs from both classes, with nodes colored by atom type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5s49gsrlz7s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample graphs from both classes\n",
    "def visualize_mutag_samples(dataset, num_samples=5, random_seed=42):\n",
    "    \"\"\"Visualize molecular graphs with nodes colored by atom type\"\"\"\n",
    "    \n",
    "    # Find samples from both classes (at least 2 from each)\n",
    "    mutagenic_indices = [i for i, data in enumerate(dataset) if data.y.item() == 1]\n",
    "    non_mutagenic_indices = [i for i, data in enumerate(dataset) if data.y.item() == 0]\n",
    "    \n",
    "    # select half of the samples from each class there are num_samples in total\n",
    "    n = int(num_samples / 2)\n",
    "    m = num_samples - n  # Remaining samples from the other class\n",
    "    # Ensure we have enough samples\n",
    "    if len(mutagenic_indices) < n or len(non_mutagenic_indices) < m:\n",
    "        raise ValueError(\"Not enough samples in one of the classes to visualize.\")\n",
    "    selected_indices = mutagenic_indices[:n] + non_mutagenic_indices[:m]\n",
    "\n",
    "    # Define atom colors for mutagenic dataset\n",
    "    atom_names = ['C', 'O', 'Cl', 'H', 'N', 'F', 'Br', 'S', 'P', 'I', 'Na', 'K', 'Li', 'Ca']  # Common atom types in MUTAG\n",
    "    atom_colors = []\n",
    "    random.seed(random_seed)  # For reproducibility\n",
    "    for atom_name in atom_names:\n",
    "        r = random.random()\n",
    "        g = random.random()\n",
    "        b = random.random()\n",
    "        atom_colors.append((r, g, b))\n",
    "    # let's define some specific colors for common atoms in MUTAG based on traditional coloring from organic chemistry\n",
    "    atom_colors[0] = (0,0,0)\n",
    "    atom_colors[1] = (1,0,0)  # O is red\n",
    "    atom_colors[2] = (0,1,0)  # Cl is green\n",
    "    atom_colors[3] = (.9,.9,.9)  # H is off-white to distinguish from white background\n",
    "    atom_colors[4] = (0,0,1)  # N is blue\n",
    "    atom_colors[5] = (0,1,1)  # F is cyan\n",
    "    atom_colors[6] = (150/255, 75/255, 0)  # Br is brown\n",
    "    atom_colors[7] = (1,1,0)  # S is yellow\n",
    "    atom_colors[8] = (1,165/255,0)  # P is orange\n",
    "\n",
    "    # only put 5 samples per row in the subplot\n",
    "    # Create subplots\n",
    "    if num_samples > 5:\n",
    "        num_rows = (num_samples + 4) // 5\n",
    "    else:\n",
    "        num_rows = 1\n",
    "    fig, axes = plt.subplots(num_rows, 5, figsize=(20, 4 * num_rows))\n",
    "    axes = axes.flatten() if num_rows > 1 else [axes]  # Flatten if multiple rows\n",
    "\n",
    "    for idx, graph_idx in enumerate(selected_indices):\n",
    "        data = dataset[graph_idx]\n",
    "        \n",
    "        # Convert to NetworkX\n",
    "        G = to_networkx(data, to_undirected=True, remove_self_loops=True)\n",
    "        \n",
    "        # Get atom types (argmax of one-hot encoding)\n",
    "        atom_types = data.x.argmax(dim=1).numpy()\n",
    "        node_colors = [atom_colors[atom_type] for atom_type in atom_types]\n",
    "        \n",
    "        # Create layout\n",
    "        pos = nx.spring_layout(G, seed=42, k=1, iterations=50)\n",
    "        \n",
    "        # Draw the graph\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=300, \n",
    "                              alpha=0.8, ax=axes[idx])\n",
    "        nx.draw_networkx_edges(G, pos, alpha=0.6, width=2, edge_color='gray', ax=axes[idx])\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8, font_color='black', ax=axes[idx])\n",
    "        \n",
    "        # Set title\n",
    "        label = 'Mutagenic' if data.y.item() == 1 else 'Non-mutagenic'\n",
    "        axes[idx].set_title(f'{label}\\n{data.x.size(0)} nodes, {data.edge_index.size(1)//2} edges', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # add a legend for atom types\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                   markerfacecolor=atom_colors[i], markersize=10,\n",
    "                                   label=f'{atom_names[i]}')\n",
    "                       for i in range(len(atom_colors))]\n",
    "    axes[-1].legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1), \n",
    "                    title='Atom Types', title_fontsize=12, fontsize=10)\n",
    "    plt.suptitle('MUTAG Dataset: Sample Molecular Graphs', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'mutag_sample_graphs.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples\n",
    "visualize_mutag_samples(dataset, 10, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "btb1xqtkehh",
   "metadata": {},
   "source": [
    "Next, let's examine the balance between mutagenic and non-mutagenic compounds in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mvjneb194tl",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "mutag_class_names = ['Non-mutagenic', 'Mutagenic']\n",
    "total_samples = len(dataset)\n",
    "\n",
    "# Count samples in each class\n",
    "class_counts = [0, 0]\n",
    "for data in dataset:\n",
    "    class_counts[data.y.item()] += 1\n",
    "\n",
    "# Bar plot\n",
    "colors = ['#FF6B6B', '#4ECDC4']  # Red for non-mutagenic, teal for mutagenic\n",
    "bars = ax.bar(range(len(mutag_class_names)), [class_counts[i] for i in range(len(mutag_class_names))], \n",
    "              color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Class', fontsize=12)\n",
    "ax.set_ylabel('Number of Compounds', fontsize=12)\n",
    "ax.set_title('MUTAG Dataset: Class Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(range(len(mutag_class_names)))\n",
    "ax.set_xticklabels(mutag_class_names)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "            f'{int(height)} ({(height/total_samples)*100:.1f}%)', \n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mutag_class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0jprzj7kt74",
   "metadata": {},
   "source": [
    "Finally, let's analyze the structural properties of the molecular graphs, including size statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bmziw5wi7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze graph properties\n",
    "def analyze_graph_properties(dataset):\n",
    "    \"\"\"Compute statistics about graph structure\"\"\"\n",
    "    num_nodes = []\n",
    "    num_edges = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for data in dataset:\n",
    "        num_nodes.append(data.x.size(0))\n",
    "        num_edges.append(data.edge_index.size(1) // 2)  # Divide by 2 for undirected edges\n",
    "        labels_list.append(data.y.item())\n",
    "\n",
    "    return np.array(num_nodes), np.array(num_edges), np.array(labels_list)\n",
    "\n",
    "# Analyze properties\n",
    "num_nodes, num_edges, labels_array = analyze_graph_properties(dataset)\n",
    "\n",
    "# Create box plots of graph sizes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Prepare data for box plots\n",
    "nodes_by_class = [num_nodes[labels_array == i] for i in range(len(mutag_class_names))]\n",
    "edges_by_class = [num_edges[labels_array == i] for i in range(len(mutag_class_names))]\n",
    "\n",
    "# Nodes box plot\n",
    "bp1 = axes[0].boxplot(nodes_by_class, labels=mutag_class_names, patch_artist=True)\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "for patch, color in zip(bp1['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "axes[0].set_xlabel('Class', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Nodes', fontsize=12)\n",
    "axes[0].set_title('Graph Size Distribution (Nodes)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Edges box plot\n",
    "bp2 = axes[1].boxplot(edges_by_class, labels=mutag_class_names, patch_artist=True)\n",
    "for patch, color in zip(bp2['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "axes[1].set_xlabel('Class', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Edges', fontsize=12)\n",
    "axes[1].set_title('Graph Size Distribution (Edges)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mutag_graph_size_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6m1952re39d",
   "metadata": {},
   "source": [
    "### 3.2 Graph-Based Feature Engineering: Graph Measures\n",
    "\n",
    "Unlike node classification where we computed centrality measures for individual nodes, graph classification requires features that characterize entire graphs. These graph-level metrics capture different structural properties of molecular compounds that may be predictive of mutagenicity.\n",
    "\n",
    "### Graph-Level Measures Overview\n",
    "\n",
    "1. **Mean Node Degree Centrality**: Average connectivity across all nodes\n",
    "   - *Interpretation*: Overall connectivity density of the molecule\n",
    "   - *NetworkX*: [`nx.degree_centrality()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.degree_centrality.html)\n",
    "\n",
    "2. **Degree Assortativity**: Tendency for nodes to connect to similar-degree nodes\n",
    "   - *Interpretation*: Whether highly connected atoms tend to connect to other highly connected atoms\n",
    "   - *NetworkX*: [`nx.degree_assortativity_coefficient()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.assortativity.degree_assortativity_coefficient.html)\n",
    "\n",
    "3. **Graph Diameter**: Longest shortest path between any two nodes\n",
    "   - *Interpretation*: Maximum \"distance\" across the molecule\n",
    "   - *NetworkX*: [`nx.diameter()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.distance_measures.diameter.html)\n",
    "\n",
    "4. **Average Betweenness Centrality**: Mean betweenness centrality across all nodes\n",
    "   - *Interpretation*: Average tendency for atoms to lie on shortest paths between other atoms\n",
    "   - *NetworkX*: [`nx.betweenness_centrality()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html)\n",
    "\n",
    "5. **Average Eigenvector Centrality**: Mean eigenvector centrality across all nodes\n",
    "   - *Interpretation*: Average importance of atoms based on connections to other important atoms\n",
    "   - *NetworkX*: [`nx.eigenvector_centrality()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.eigenvector_centrality.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3g5kg3ee8g2",
   "metadata": {},
   "source": [
    "Now let's compute these graph-level features for each molecular graph in the MUTAG dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z4hwigj2x7l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute graph-level features for all MUTAG graphs\n",
    "def compute_graph_features(dataset):\n",
    "    \"\"\"Compute graph-level features for each molecular graph\"\"\"\n",
    "    \n",
    "    # Initialize feature storage\n",
    "    features = {\n",
    "        'mean_degree_centrality': [],\n",
    "        'degree_assortativity': [],\n",
    "        'diameter': [],\n",
    "        'mean_betweenness_centrality': [],\n",
    "        'mean_eigenvector_centrality': [],\n",
    "        'labels': []\n",
    "    }\n",
    "    \n",
    "    print(\"Computing graph features...\")\n",
    "    print(f\"Processing {len(dataset)} graphs...\")\n",
    "    \n",
    "    for i, data in enumerate(dataset):\n",
    "        if (i + 1) % 50 == 0 or i == 0:\n",
    "            print(f\"  Progress: {i+1}/{len(dataset)} graphs processed\")\n",
    "        \n",
    "        # Convert PyTorch Geometric graph to NetworkX\n",
    "        G = to_networkx(data, to_undirected=True, remove_self_loops=True)\n",
    "        \n",
    "        # Store label\n",
    "        features['labels'].append(data.y.item())\n",
    "        \n",
    "        try:\n",
    "            # 1. Mean node degree centrality\n",
    "            degree_cent = nx.degree_centrality(G)\n",
    "            features['mean_degree_centrality'].append(np.mean(list(degree_cent.values())))\n",
    "            \n",
    "            # 2. Degree assortativity coefficient\n",
    "            try:\n",
    "                assortativity = nx.degree_assortativity_coefficient(G)\n",
    "                features['degree_assortativity'].append(assortativity if not np.isnan(assortativity) else 0.0)\n",
    "            except:\n",
    "                features['degree_assortativity'].append(0.0)\n",
    "            \n",
    "            # 3. Graph diameter (handle disconnected graphs)\n",
    "            try:\n",
    "                if nx.is_connected(G):\n",
    "                    diameter = nx.diameter(G)\n",
    "                else:\n",
    "                    # For disconnected graphs, use the maximum diameter of connected components\n",
    "                    diameters = []\n",
    "                    for component in nx.connected_components(G):\n",
    "                        subgraph = G.subgraph(component)\n",
    "                        if len(component) > 1:  # Avoid single-node components\n",
    "                            diameters.append(nx.diameter(subgraph))\n",
    "                    diameter = max(diameters) if diameters else 0\n",
    "                features['diameter'].append(diameter)\n",
    "            except:\n",
    "                features['diameter'].append(0)\n",
    "            \n",
    "            # 4. Average betweenness centrality\n",
    "            try:\n",
    "                betweenness_cent = nx.betweenness_centrality(G, normalized=True)\n",
    "                features['mean_betweenness_centrality'].append(np.mean(list(betweenness_cent.values())))\n",
    "            except:\n",
    "                features['mean_betweenness_centrality'].append(0.0)\n",
    "            \n",
    "            # 5. Average eigenvector centrality\n",
    "            try:\n",
    "                eigenvector_cent = nx.eigenvector_centrality(G, max_iter=1000, tol=1e-06)\n",
    "                features['mean_eigenvector_centrality'].append(np.mean(list(eigenvector_cent.values())))\n",
    "            except:\n",
    "                # Eigenvector centrality can fail for disconnected graphs or graphs with certain structures\n",
    "                features['mean_eigenvector_centrality'].append(0.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing graph {i}: {e}\")\n",
    "            # Add default values for failed computations\n",
    "            features['mean_degree_centrality'].append(0.0)\n",
    "            features['degree_assortativity'].append(0.0)\n",
    "            features['diameter'].append(0)\n",
    "            features['mean_betweenness_centrality'].append(0.0)\n",
    "            features['mean_eigenvector_centrality'].append(0.0)\n",
    "    \n",
    "    print(f\"Feature computation completed!\")\n",
    "    return features\n",
    "\n",
    "# Compute features\n",
    "graph_features = compute_graph_features(dataset)\n",
    "\n",
    "# Convert to numpy arrays for easier manipulation\n",
    "feature_names = ['mean_degree_centrality', 'degree_assortativity', 'diameter', \n",
    "                'mean_betweenness_centrality', 'mean_eigenvector_centrality']\n",
    "\n",
    "feature_matrix = np.column_stack([\n",
    "    graph_features['mean_degree_centrality'],\n",
    "    graph_features['degree_assortativity'],\n",
    "    graph_features['diameter'],\n",
    "    graph_features['mean_betweenness_centrality'],\n",
    "    graph_features['mean_eigenvector_centrality']\n",
    "])\n",
    "\n",
    "labels_array = np.array(graph_features['labels'])\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {feature_matrix.shape}\")\n",
    "print(f\"Labels shape: {labels_array.shape}\")\n",
    "\n",
    "# Display feature statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean': [np.mean(graph_features[name]) for name in feature_names],\n",
    "    'Std': [np.std(graph_features[name]) for name in feature_names],\n",
    "    'Min': [np.min(graph_features[name]) for name in feature_names],\n",
    "    'Max': [np.max(graph_features[name]) for name in feature_names],\n",
    "    'Zeros': [np.sum(np.array(graph_features[name]) == 0) for name in feature_names]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Graph-Level Feature Statistics ===\")\n",
    "print(stats_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hf4ecvdv0or",
   "metadata": {},
   "source": [
    "Let's visualize the distributions of these graph-level features to understand their variance and potential discriminative power between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lo084i2nti",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create distribution plots for graph features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Define nice feature names for plotting\n",
    "feature_display_names = [\n",
    "    'Mean Degree Centrality',\n",
    "    'Degree Assortativity',\n",
    "    'Graph Diameter',\n",
    "    'Mean Betweenness Centrality',\n",
    "    'Mean Eigenvector Centrality'\n",
    "]\n",
    "\n",
    "colors = ['#FF6B6B', '#4ECDC4']  # Red for non-mutagenic, teal for mutagenic\n",
    "\n",
    "# Plot distributions for all 5 features\n",
    "for i in range(5):\n",
    "    feature_name = feature_names[i]\n",
    "    display_name = feature_display_names[i]\n",
    "    \n",
    "    # Create histogram for each class\n",
    "    for class_idx, class_name in enumerate(mutag_class_names):\n",
    "        mask = labels_array == class_idx\n",
    "        feature_values = np.array(graph_features[feature_name])[mask]\n",
    "        \n",
    "        axes[i].hist(feature_values, bins=15, alpha=0.7, \n",
    "                    label=f'{class_name} ({np.sum(mask)} graphs)',\n",
    "                    color=colors[class_idx], edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    axes[i].set_xlabel(display_name, fontsize=11)\n",
    "    axes[i].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[i].set_title(f'{display_name}\\\\nMean: {np.mean(graph_features[feature_name]):.3f}, Std: {np.std(graph_features[feature_name]):.3f}', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[i].legend(fontsize=9)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Remove the empty subplot (since we only have 5 features now)\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.suptitle('MUTAG Dataset: Graph-Level Feature Distributions', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mutag_graph_feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create correlation heatmap of graph features\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create correlation matrix\n",
    "graph_df = pd.DataFrame(feature_matrix, columns=feature_display_names)\n",
    "correlation_matrix = graph_df.corr()\n",
    "\n",
    "# Create heatmap\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.title('Graph-Level Feature Correlation Matrix\\\\nMUTAG Dataset', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mutag_graph_feature_correlations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t44qho3pn09",
   "metadata": {},
   "source": [
    "### 3.3 Logistic Regression with Graph Metrics\n",
    "\n",
    "We'll train and evaluate a **logistic regression model** using the graph-level features to predict molecular mutagenicity. This follows the same methodology as Section 2 but adapted for binary graph classification.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. **Data Splitting**: Split the data into train/test sets (80%/20%) with feature standardization\n",
    "2. **Model Training**: Logistic regression with regularization using grid search and cross-validation\n",
    "3. **Hyperparameter Tuning**: 5-fold cross-validation to optimize regularization parameters \n",
    "4. **Performance Analysis**: Classification reports, confusion matrices, and ROC-AUC curves\n",
    "\n",
    "**Key Differences from Enron Node Classification:**\n",
    "- **Binary classification** (mutagenic vs non-mutagenic) instead of multi-class\n",
    "- **Graph-level features** instead of individual node measures (though with some aggregated node feautres)\n",
    "- **Smaller dataset** (188 graphs vs 4,203 nodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o4iflkodope",
   "metadata": {},
   "source": [
    "First, let's split the data into training and test sets, and standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cmhb0heygpc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting for MUTAG graph classification\n",
    "X = feature_matrix.copy()\n",
    "y = labels_array.copy()\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape} | Labels shape: {y.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y)} (0: Non-mutagenic, 1: Mutagenic)\")\n",
    "\n",
    "# Split the data into train/test sets (80%/20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} samples | Test: {X_test.shape[0]} samples\")\n",
    "print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7npqyh92ise",
   "metadata": {},
   "source": [
    "Now let's create a logistic regression model with hyperparameter tuning using grid search and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mh0h12tqob",
   "metadata": {},
   "source": [
    "#### **Exercise 3.1**\n",
    "Complete the code below to create a LogisticRegression base model with the following parameters:\n",
    "- solver='liblinear' (good for small datasets)\n",
    "- random_state=RANDOM_STATE \n",
    "- max_iter=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082jlctamrpc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter search space\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2']               # Regularization type\n",
    "}\n",
    "\n",
    "# Exercise 3.1: Create the base model\n",
    "base_model = ___  # Your code here\n",
    "\n",
    "# Grid search with cross-validation\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "grid_search = GridSearchCV(\n",
    "    base_model,\n",
    "    param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='roc_auc',  # Use ROC-AUC for binary classification\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "votxgj7btf",
   "metadata": {},
   "source": [
    "Let's evaluate the model performance on the test set with a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cxe7v0pnx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_test_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(\"=== MUTAG Test Set Classification Report ===\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=mutag_class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8lh8yhz7xu",
   "metadata": {},
   "source": [
    "Next, let's visualize the confusion matrix to understand the classification errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uczvy26wjco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# Create confusion matrix with normalize='pred'\n",
    "cm = confusion_matrix(y_test, y_test_pred, normalize='pred')\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', \n",
    "            xticklabels=mutag_class_names, yticklabels=mutag_class_names,\n",
    "            cbar_kws={'label': 'Proportion'}, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "ax.set_title('MUTAG: Confusion Matrix', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add count annotations\n",
    "cm_counts = confusion_matrix(y_test, y_test_pred)\n",
    "for i in range(len(mutag_class_names)):\n",
    "    for j in range(len(mutag_class_names)):\n",
    "        ax.text(j + 0.5, i + 0.7, f'({cm_counts[i,j]})', \n",
    "               ha='center', va='center', fontsize=10, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mutag_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42r1djh9o8",
   "metadata": {},
   "source": [
    "Now, let's create an ROC curve to visualize the model's performance across different classification thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r28q42kbg2",
   "metadata": {},
   "source": [
    "#### **Exercise 3.2**\n",
    "Complete the code below to compute the false positive rate (fpr) and true positive rate (tpr) for the ROC curve.\n",
    "\n",
    "**Hint**: Use the `roc_curve` function from sklearn.metrics with `y_test` and `y_test_proba` as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ls10vrkd6w",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = best_model.predict_proba(X_test_scaled)[:, 1]  # Probability of positive class (mutagenic)\n",
    "\n",
    "# Exercise 3.2: Compute ROC curve\n",
    "fpr, tpr, thresholds = ___  # Your code here\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create ROC plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# Plot ROC curve\n",
    "ax.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "        label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# Plot random classifier line\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', alpha=0.5,\n",
    "        label='Random Classifier (AUC = 0.50)')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('MUTAG: ROC Curve for Graph Classification', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc=\"lower right\", fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'mutag_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278ca98",
   "metadata": {},
   "source": [
    "Finally, let's examine the feature importance by reviewing the logistic regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63996407",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = best_model.coef_\n",
    "# This is binary classification, so coeffs will have shape (1, n_features)\n",
    "print(\"Logistic Regression Coefficients Shape:\")\n",
    "print(coeffs.shape)\n",
    "\n",
    "for fn, coef in zip(feature_display_names, coeffs[0]):\n",
    "    print(f\"{fn}: {coef:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g",
   "language": "python",
   "name": "ml4g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
